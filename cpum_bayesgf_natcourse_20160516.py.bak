#!/usr/bin/env python
# Bayesian g-formula for non-white uranium miners


import sas7bdat as sas
import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import statsmodels.formula.api as smf
import time
from numpy import random
from collections import deque
import numba

# global variables
keepcols = list(set(['id', 'agein', 'BL_cumwlmcen', 'BL_cumyrsexpcen', 'cohort_1', 
        'atwork2lag', 'cumwlm2lagcen', 'ageoutcen', 'ageoutcensq', 
        'ageoutcencu', 'ageoutcenqu', 'atwork', 'cumwlm2lagcensq', 'cumwlm',
        'dateoutcen', 'dateoutcensq', 'd_lc', 'd_any', 'd_nonlc', 'wlm',
        'logwlm1000', 'wlm1000', 'cumyrsexpcen', 'cumyrsexpcensq', 'leftwork',
        'datein', 'dateout', 'ageout', 'cohort', 'ageatadmincens',
        'eligage','BL_cumwlm', 'BL_cumyrsexp', 'cumyrsexp', 'cumwlm2lag']))



pd.options.mode.chained_assignment = None  # turn off annoying warning (also time consuming)

# three functions to automate model making
def pd_to_npmat(x = ['id'], df='df', int=True, pr=False):
    if int:
        ones = "np.ones(len(" + df + "['" + x[0] + "'])), "
    ndf = ", " + df + "['"
    cs = [i.replace(":", "'] * " + df + "['") + "']" for i in x] # 1.69 mins
    conv_mat = "np.column_stack(("+ ones + df + "['" + ndf.join(cs) + "))"
    #cs = [i.replace(":", "'].values * " + df + "['") + "'].values" for i in x] # 1.68 mins
    #conv_mat = "np.column_stack(("+ ones + df + "['" + ndf.join(cs) + "))"
    if pr:
        print("Pandas to matrix code")
        print(conv_mat)
    return conv_mat


def pd_to_nparrays(x = ['id'], df='df', pr=False):
    '''
    usage: [eval(st) for st in pd_to_nparrays()]
    '''
    stx = set([j  for i in x for j in i.split(':')])
    code_array = [v + " = np.array("+ df +"['" + v + "'])\n" for v in stx] # 1.68 mins (sim only) for 10k iters
    #code_array = [v + " = "+ df +"['" + v + "'].values\n" for v in stx] # 1.88 mins (sim only) for 10k iters
    return code_array


def sm_to_pred(x = ['id'], idx='i', pr=False):
    np_code = [i.replace(':', '[' + idx + '] * ') for i in x]
    idx_join = '['+ idx + '], '
    if idx == ':':
        leftedge = 'np.column_stack(('
        rightedge = '))'
        one = 'np.ones(len(' + x[0] + '))'
    else:
        one = '1.0'
        leftedge = '['
        rightedge = ']'
    smi_code = leftedge + one + ', ' +  idx_join.join(np_code) + '['+ idx + ']' + rightedge
    if pr:
        print("Statsmodels.api predict code")
        print(smi_code)
    return smi_code



def smf_to_pred(x = ['id'], pr=False):
    smf_code = ' + '.join(x)
    if pr:
        print("Statsmodels.formula.api model code")
        print(smf_code)
    return smf_code


def center_var(var=None, mn=None, sd=None):
    if mn is None:
        res = (var - var.mean())/var.std()
    else:
        res = (var - mn)/sd
    return res


def proc_dat(df, keepcols=keepcols):
    cenvars = ['BL_cumwlm', 'BL_cumyrsexp', 'cumyrsexp', 'cumwlm2lag', 
                'ageout', 'dateout']            
    for cv in cenvars:
        df.loc[:,'{}cen'.format(cv)] = center_var(df.loc[:,cv])
    
    df.loc[:,'ageoutcensq'] = df.loc[:,'ageoutcen']*df.loc[:,'ageoutcen']
    df.loc[:,'ageoutcencu'] = df.loc[:,'ageoutcensq']*df.loc[:,'ageoutcen']
    df.loc[:,'ageoutcenqu'] = df.loc[:,'ageoutcensq']*df.loc[:,'ageoutcensq']
    df.loc[:,'cohort_1'] = df.loc[:,'cohort'].apply(lambda x: 1 if x <= 2 else 0)
    df.loc[:,'dateoutcensq'] = df.loc[:,'dateoutcen']*df.loc[:,'dateoutcen']
    df.loc[:,'cumwlm2lagcensq'] = (df.loc[:,'cumwlm2lagcen']*
                                  df.loc[:,'cumwlm2lagcen'])
    df.loc[:,'cumyrsexpcensq'] = df.loc[:,'cumyrsexpcen']*df.loc[:,'cumyrsexpcen']
    df.loc[:,'intercept'] = 1.0
    df.loc[:,'wlm1000'] = df.loc[:,'wlm']*1000.0
    df.loc[:,'logwlm1000'] = np.log(df.loc[:,'wlm1000'])

    return df.loc[:,keepcols].copy()

def select_bl(df):
    #keepcols = ['id', 'datein', 'BL_cumwlmcen', 'BL_cumyrsexpcen',
    #            'agein', 'cohort_1', 'cohort', 'eligage', 'ageatadmincens']
    df['firstobs'] = (df.groupby('id').cumcount() == 0)
    res =  df.loc[df['firstobs'], keepcols]
    return res


# capturing centering variables
def mk_mcdata(bldf, adf, samp_size=12):

    mcdat = bldf.sample(n=samp_size, replace=True).copy()
    mcdat['cumyrsexp'] = 0.0
    mcdat['cumwlm2lag'] = 0.0
    mcdat['maxtime'] = (mcdat.loc[:,'ageatadmincens'] - 
                        mcdat.loc[:,'agein'] - 1.0)
    mcdat['copyrows'] = np.ceil(mcdat.loc[:,'maxtime'])
    
    mcdat.reset_index(drop=True, inplace=True)
    mcdat['oldid'] = mcdat['id'].copy()
    mcdat['id'] = mcdat.index
    print('MC sample size: {}'.format(samp_size))
    return mcdat


def mk_gfdata(df, adf):
    # create large, empty dataset from mc baseline sample   
    cenvars = ['ageout', 'dateout']
    for cv in cenvars:
        mns = adf.loc[:, cenvars].mean()
        sds = adf.loc[:, cenvars].std()
    newidx = [] 
    for idx, row in df.iterrows():
        [newidx.append(i) for i in [idx]*int(row['copyrows'])]
    
    # empty data frame
    gf = pd.DataFrame(index = newidx, columns=keepcols + ['oldid'])
    
    # fill with baseline data
    gf.update(df)
    gf.reset_index(drop=True, inplace=True)
    gf = gf.astype(float)
    # set some defaults
    gf['atwork'] = 1
    gf['leftwork'] = 0
    gf['cumwlm'] = 0.0
    gf['cumwlm2lag'] = 0.0
    gf['atwork2lag'] = 1
    gf['atwork'] = gf['atwork'].astype(int)
    gf['leftwork'] = gf['leftwork'].astype(int)
    # set deterministic variables
    gf['agein'] = gf['agein'].copy() + gf.groupby('id').cumcount()
    gf['ageout'] = 1.0 + gf['agein']
    gf['datein'] = gf['datein'].copy() + gf.groupby('id').cumcount()
    gf['dateout'] = 1.0 + gf['datein']
    for cv in ['ageout', 'dateout']:
        gf.loc[:,'{}cen'.format(cv)] = center_var(gf.loc[:,cv], 
                                        mns.loc[cv], sds.loc[cv])
    gf.loc[:,'ageoutcensq'] = gf.loc[:,'ageoutcen']**2
    gf.loc[:,'ageoutcencu'] = (gf.loc[:,'ageoutcensq']*
                               gf.loc[:,'ageoutcen'])
    gf.loc[:,'ageoutcenqu'] = gf.loc[:,'ageoutcensq']**2
    gf.loc[:,'dateoutcensq'] = gf.loc[:,'dateoutcen']**2

    return gf[gf['ageout']<91]


def intervention(df=None, adf=None, xmod=None, wmod=None, 
                lcmod=None, nlcmod=None):
    cenvars = ['cumyrsexp', 'cumwlm2lag']
    for cv in cenvars:
        mns = adf.loc[:, cenvars].mean()
        sds = adf.loc[:, cenvars].std()
    gfst = time.time()
    # take some external stats for centering purposes
    # model scale for exposure model
    scale = np.sqrt(xmod.mse_resid)
    #convert pandas df to numpy arrays
    df = df.copy() # no difference in runtime
    df_conv = pd_to_nparrays(lcmat + nlcmat + xmat + wmat + keepcols + ['oldid'], 'df')
    for conv in df_conv:
        exec(conv, locals(), globals())
    # placeholders for below
    lendf = df.shape[0]
    d_lc = np.zeros(lendf)
    d_nonlc =  np.zeros(lendf)
    h_lc =  np.zeros(lendf)
    h_nlc =  np.zeros(lendf)

    lastid = -1
    lastcumwlm = 0
    ctr = 0
    for idx in range(lendf):
        # if new id, set at work varialb
        if (ctr == 0) or (id[idx] != lastid):
            isdead = 0
            lastcumwlm = 0
            lastcumyrsexp = 0
            expd2 = deque([0,0], maxlen=2)
            workd2 = deque([0,0], maxlen=2)
            atwork[idx] = 1
        # if same id, then advance age, date by one year
        else:
            atwork[idx] = workd2[1] # take right hand side of deque (most recent)
        
        # pop the oldest value from the cum. exposure, work variable
        cumwlm2lag[idx] = expd2.popleft()
        atwork2lag[idx] = workd2.popleft()
        cumyrsexpcen[idx] = center_var(cumyrsexp[idx], mns.loc['cumyrsexp'], sds.loc['cumyrsexp'])
        cumwlm2lagcen[idx] = center_var(cumwlm2lag[idx], mns.loc['cumwlm2lag'], sds.loc['cumwlm2lag'])
        cumyrsexpcensq[idx] = cumyrsexpcen[idx]**2
        cumwlm2lagcensq[idx] = cumwlm2lagcen[idx]**2

        # employment status
        if (ctr == 0) or (id[idx] != lastid):
            # forced labor for first year
            cumyrsexp[idx] = 1.
        elif atwork[idx] == 1 and dateout[idx] < 1970.5:
            wmatcode = sm_to_pred(wmat, idx='idx')
            lw = random.binomial(1, wmod.predict(eval(wmatcode))[0])
            if lw == 1:
                leftwork[idx] = 1
                atwork[idx] = 0
            elif (ctr > 0) and (id[idx] == lastid):
                cumyrsexp[idx] = lastcumyrsexp + 1.
            else:
                cumyrsexp[idx] = 1.
        else:
            atwork[idx] = 0
            leftwork[idx] = 0
        # exposure
        if atwork[idx] == 1:
            xmatcode = sm_to_pred(xmat, idx='idx')
            wlm1000[idx] = np.exp(random.normal(xmod.predict(eval(xmatcode)), scale))
            wlm[idx] = wlm1000[idx]/1000
        else:
            wlm1000[idx] = 0
            wlm[idx] = 0
        if (idx > 0) and (id[idx] == lastid):
            cumwlm[idx] = lastcumwlm + wlm[idx]
        else:
            cumwlm[idx] = wlm[idx]
        # add to lagged variable container
        expd2.append(cumwlm[idx])
        workd2.append(atwork[idx])

        #end of loop in current time, set values for time idx + 1
        isdead = d_lc[idx] + d_nonlc[idx]
        lastid = id[idx]
        ctr += 1
        lastcumwlm = cumwlm[idx]
        lastcumyrsexp = cumyrsexp[idx]
    # end age loop
    # mortality (just taking expectation)
    ########
    lcmatcode = sm_to_pred(lcmat, idx=':')
    nlcmatcode = sm_to_pred(nlcmat, idx=':')
    h_lc = lcmod.predict(eval(lcmatcode))
    h_nlc = nlcmod.predict(eval(nlcmatcode))
    d_lc = random.binomial(1, h_lc)
    d_nonlc[d_lc==0] = random.binomial(1, h_nlc[d_lc==0])
    d_any = d_lc + d_nonlc
    gfe = time.time()
    print("Array based simulation time (minutes): {:.2f}".format((gfe-gfst)/60))
    return (id, oldid, ageout, dateout, wlm, cumwlm, atwork, cumyrsexp,
            wlm1000, BL_cumwlmcen, BL_cumyrsexpcen, 
            cohort_1, cumwlm2lag, atwork2lag, h_lc, h_nlc, ageoutcen,
            ageoutcencu, ageoutcenqu,d_lc, d_nonlc,
            ageoutcensq, cumyrsexpcensq, dateoutcen, dateoutcensq)





def ci_calc(gf):
    df = gf.copy()
    df['ageout'] = np.round(df['ageout'])
    hdat = df.groupby('ageout').mean()[['h_lc', 'h_nlc']]
    hdat['ch'] = np.cumsum(hdat['h_lc'] + hdat['h_nlc'])
    hdat['surv'] = np.exp(-hdat['ch'])
    hdat['survlag'] = 1.0
    ctr = 0
    for idx in hdat.index:
        if ctr > 0:
            hdat.loc[idx, 'survlag'] = hdat.loc[idx-1, 'surv']
        ctr += 1
    hdat['ci_lc'] = np.cumsum(hdat['h_lc'] * hdat['survlag'])
    hdat['ci_nlc'] = np.cumsum(hdat['h_nlc'] * hdat['survlag'])
    hdat['ageout'] = hdat.index
    
    return hdat[hdat['ageout'] <= 90.0]


st = time.time()

datdir = '/Users/akeil/EpiProjects/CPUM/data/'

#dat = sas.SAS7BDAT('{}an0001.sas7bdat'.format(datdir)).to_data_frame()
with open('{}an0001.pkl'.format(datdir), 'rb') as f:
    dat = pickle.load(f)

rdt = time.time()
print("Reading data = {:.2f} minutes".format((rdt-st)/60))


dat.shape
dat.columns
nadat = dat.loc[dat.race == 2,:]
#nadat = dat


adat = proc_dat(nadat)
bldat = select_bl(adat)
proct = time.time()
print("Processing data = {:.2f} minutes".format((proct - rdt) / 60))


lcmat = ['BL_cumwlmcen', 'BL_cumyrsexpcen', 'cohort_1', 'cumyrsexpcen', 'atwork2lag', 
         'cumwlm2lagcen', 'ageoutcen', 'ageoutcensq', 'ageoutcencu', 'ageoutcenqu', 
         'atwork:cumwlm2lagcen', 'cumyrsexpcensq', 'dateoutcen', 'dateoutcensq']

nlcmat = ['BL_cumwlmcen', 'BL_cumyrsexpcen', 'cohort_1', 'cumyrsexpcen', 'atwork2lag', 
          'cumwlm2lagcen', 'ageoutcen', 'ageoutcensq', 'ageoutcencu', 'ageoutcenqu', 
          'atwork:cumwlm2lagcen', 'cumyrsexpcensq', 'dateoutcen', 'dateoutcensq']

wmat = ['BL_cumwlmcen', 'BL_cumyrsexpcen', 'cohort_1', 'cumwlm2lagcen', 'ageoutcen', 
        'ageoutcensq', 'cumyrsexpcensq', 'dateoutcen', 'dateoutcensq']

xmat = ['BL_cumwlmcen', 'BL_cumyrsexpcen', 'cohort_1', 'atwork2lag', 'cumwlm2lagcen', 
        'ageoutcen', 'ageoutcensq', 'ageoutcencu', 'ageoutcenqu', 'atwork:cumwlm2lagcen', 
        'cumyrsexpcensq', 'dateoutcen', 'dateoutcensq']


flc = 'd_lc ~ ' + smf_to_pred(lcmat)
fnlc = 'd_nonlc ~ ' + smf_to_pred(nlcmat)
fw = 'leftwork ~ ' + smf_to_pred(wmat)
fx = 'logwlm1000 ~ ' + smf_to_pred(xmat)

wdat = adat[(adat['atwork']==1) | (adat['leftwork']==1)]
xdat = adat[adat['wlm'] > 0]


# modeling
lc_logit = smf.logit(flc, data=adat).fit(disp=False)
nlc_logit = smf.logit(fnlc, data=adat).fit(disp=False)
w_logit = smf.logit(fw, data=wdat).fit(disp=False)
x_ols = smf.ols(fx, data=xdat).fit(disp=False)



lccode = pd_to_npmat(lcmat, 'adat')
nlccode = pd_to_npmat(lcmat, 'adat')
wcode = pd_to_npmat(wmat, 'wdat')
xcode = pd_to_npmat(xmat, 'xdat')


lc_logitm = sm.Logit(adat['d_lc'], eval(lccode)).fit(disp=False)
nlc_logitm = sm.Logit(adat['d_nonlc'], eval(nlccode)).fit(disp=False)
w_logitm = sm.Logit(wdat['leftwork'], eval(wcode)).fit(disp=False)
x_olsm = sm.OLS(xdat['logwlm1000'], eval(xcode)).fit(disp=False)

# Monte carlo sampling
mcdata = mk_mcdata(bldat, adf=adat, samp_size=50000)
gformula = mk_gfdata(df=mcdata, adf=adat)

# need to keep in order since the second one modifies gformula
(id, oldid, ageout, dateout, wlm, cumwlm, atwork, cumyrsexp,
    wlm1000, BL_cumwlmcen, BL_cumyrsexpcen, 
    cohort_1, cumwlm2lag, atwork2lag, h_lc, h_nlc, ageoutcen,
    ageoutcencu, ageoutcenqu,d_lc, d_nonlc,
    ageoutcensq, cumyrsexpcensq, dateoutcen, dateoutcensq) = intervention(
            df=gformula, adf=adat, xmod = x_olsm, 
            wmod= w_logitm, lcmod=lc_logitm, nlcmod=nlc_logitm)

cidf = pd.DataFrame(np.column_stack((id, oldid, ageout, dateout, wlm, cumwlm, atwork, cumyrsexp,
    wlm1000, BL_cumwlmcen, BL_cumyrsexpcen, 
    cohort_1, cumwlm2lag, atwork2lag, h_lc, h_nlc, ageoutcen,
    ageoutcencu, ageoutcenqu,d_lc, d_nonlc,
    ageoutcensq, cumyrsexpcensq, dateoutcen, dateoutcensq)), 
        columns=['id', 'oldid', 'ageout', 'dateout', 'wlm', 'cumwlm', 'atwork', 'cumyrsexp',
        'wlm1000', 'BL_cumwlmcen', 'BL_cumyrsexpcen', 
        'cohort_1', 'cumwlm2lag', 'atwork2lag', 'h_lc', 'h_nlc', 'ageoutcen',
        'ageoutcencu', 'ageoutcenqu','d_lc', 'd_nonlc',
        'ageoutcensq', 'cumyrsexpcensq', 'dateoutcen', 'dateoutcensq'])


cidata2 = ci_calc(cidf)


nadat.loc[:,'h_lc'] = lc_logit.predict(nadat)
nadat.loc[:,'h_nlc'] = nlc_logit.predict(nadat)
nadat.loc[:,'oldid'] = nadat.loc[:,'id']
ciobs = ci_calc(nadat)



checkvars = ['ageout', 'dateout', 'wlm', 'cumyrsexp', 'atwork']
nadat[checkvars].mean()
cidf[checkvars].mean()

keepers = ['id', 'oldid', 'ageout', 'dateout', 'wlm', 'cumwlm', 'atwork', 'cumyrsexp',
        'wlm1000', 'BL_cumwlmcen', 'BL_cumyrsexpcen', 
        'cohort_1', 'cumwlm2lag', 'atwork2lag', 'h_lc', 'h_nlc', 'ageoutcen',
        'ageoutcencu', 'ageoutcenqu','d_lc', 'd_nonlc',
        'ageoutcensq', 'cumyrsexpcensq', 'dateoutcen', 'dateoutcensq' ]


cidf.loc[0:5000, keepers].to_csv('/Users/akeil/temp/gf.csv', index=False )
nadat.loc[0:5000, keepers].to_csv('/Users/akeil/temp/obs.csv', index=False )
cidata2.to_csv('/Users/akeil/temp/ci_array.csv', index=False )
ciobs.to_csv('/Users/akeil/temp/ciobs.csv', index=False )



plt.plot(cidata2['ageout'], cidata2['ci_lc'], '.')
plt.plot(cidata2['ageout'], cidata2['ci_nlc'], '.')
plt.plot(ciobs['ageout'], ciobs['ci_lc'], '--')
plt.plot(ciobs['ageout'], ciobs['ci_nlc'], '--')
plt.savefig('/Users/akeil/temp/ci_fig.png')


end = time.time()
print("Runtime = {:.2f} minutes".format((end-st)/60))



